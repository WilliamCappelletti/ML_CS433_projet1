'''
functions to implement least squares using gradient descent, stochastic gradient descent or normal equation

All functions return (w,loss), which is the last weight vector of the method and the corresponding loss
'''

from costs import *
from gradient_descent import *
from stochastic_gradient_descent import *


def least_squares_GD(y, tx, initial_w, max_iters, gamma):
    
    return (w,loss)

def least_squares_SGD(y, tx, initial_w,max_iters, gamma):

    return (w,loss)

def least_squares(y,tx):

    return (w,loss)
